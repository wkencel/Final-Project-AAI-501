{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an image classifier from scratch on the Kaggle Trash Images dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import keras_cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load and Cleanup\n",
    "\n",
    "Delete any image that is corrupted and does not contain \"JFIF\" header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 0 images\n"
     ]
    }
   ],
   "source": [
    "num_skipped = 0\n",
    "\n",
    "waste_classes = [\"cardboard\",\n",
    "                 \"glass\",\n",
    "                 \"metal\",\n",
    "                 \"paper\",\n",
    "                 \"plastic\",\n",
    "                 \"trash\"]\n",
    "\n",
    "for folder_name in waste_classes:\n",
    "    folder_path = os.path.join(\"..\", \"data\", \"trash_images\", folder_name)\n",
    "    for fname in os.listdir(folder_path):\n",
    "        fpath = os.path.join(folder_path, fname)\n",
    "        try:\n",
    "            fobj = open(fpath, \"rb\")\n",
    "            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
    "        finally:\n",
    "            fobj.close()\n",
    "\n",
    "        if not is_jfif:\n",
    "            num_skipped += 1\n",
    "            # Delete corrupted image\n",
    "            os.remove(fpath)\n",
    "\n",
    "print(\"Deleted %d images\" % num_skipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "image_size = (180, 180)\n",
    "batch_size = 128\n",
    "num_classes = len(waste_classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset Generation\n",
    "\n",
    "Using batch size of 128 and image size of 180x180"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"../data/trash_images\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizing some of the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(np.array(images[i]).astype(\"uint8\"))\n",
    "        plt.title(waste_classes[labels[i]])\n",
    "        plt.axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Augmenting dataset\n",
    "\n",
    "Artificially inducing sample diversity by applying transformations to training images. <br>\n",
    "We apply random flips and rotations to help expose the model to different aspects of training data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_augmentation_layers = [\n",
    "        keras_cv.layers.RandomFlip(),\n",
    "        keras_cv.layers.RandAugment(\n",
    "            value_range=(0, 255),\n",
    "            augmentations_per_image=2,\n",
    "            magnitude=0.5,\n",
    "            magnitude_stddev=0.15,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "def data_augmentation(images):\n",
    "    for layer in data_augmentation_layers:\n",
    "        images = layer(images)\n",
    "    return images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(np.array(augmented_images[0]).astype(\"uint8\"))\n",
    "        plt.axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Synchronous Pre-Processing of Images\n",
    "\n",
    "Attempting to pre-fetch images and apply data augmentation to training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Apply `data_augmentation` to the training images.\n",
    "train_ds = train_ds.map(\n",
    "    lambda img, label: (data_augmentation(img), label),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")\n",
    "# Prefetching samples in GPU memory helps maximize GPU utilization.\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Construction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        units = 1\n",
    "    else:\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    # We specify activation=None so as to return logits\n",
    "    outputs = layers.Dense(units, activation=None)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=image_size + (3,), num_classes=6)\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=num_epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_ds,\n",
    ")\n",
    "\n",
    "model.save(f\"model_{num_epochs}_epochs.keras\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing with an image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img = keras.utils.load_img(\"../data/trash_images/cardboard/cardboard_015.jpg\", target_size=image_size)\n",
    "plt.imshow(img)\n",
    "\n",
    "img_array = keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "print(f\"Classified as {waste_classes[np.argmin(predictions)]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Individual Metrics\n",
    "This function imports the first model (base CNN) as well as the metrics saved from file and calculates the accuracy for each of our categories of trash. This is done with the validation dataset. The scores are saved off to a dictionary and will be used later."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# File holding saved trained model from above\n",
    "model_path = 'saved_models/model_50_epochs.keras'\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model(model_path)\n",
    "\n",
    "# Extract true labels from the validation dataset\n",
    "val_labels = np.concatenate([batch[1].numpy() for batch in val_ds], axis=0)\n",
    "\n",
    "# Use model to predict labels based on validation data\n",
    "val_predictions = loaded_model.predict(val_ds)\n",
    "\n",
    "# Get predicted class labels\n",
    "predicted_labels = np.argmax(val_predictions, axis=1)\n",
    "\n",
    "# List of possible categories\n",
    "categories = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "\n",
    "# Initialize dictionary to store values to be used later \n",
    "result_dict = {}\n",
    "\n",
    "# Calculate accuracy score for each category\n",
    "for i, category in enumerate(categories):\n",
    "    true_positive = np.sum((predicted_labels == i) & (val_labels == i))\n",
    "    total_true = np.sum(val_labels == i)\n",
    "    accuracy = true_positive / total_true if total_true > 0 else 0.0\n",
    "    \n",
    "    # Save values off to the result_dict and print out\n",
    "    result_dict[f'{category}'] = accuracy\n",
    "    print(f'Category {category} Accuracy: {accuracy}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Attempting EfficientNetV2Backbone Instead"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing with improved augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "augmenter = keras_cv.layers.Augmenter(\n",
    "    [\n",
    "        keras_cv.layers.RandomFlip(),\n",
    "        keras_cv.layers.RandAugment(value_range=(0, 255)),\n",
    "        keras_cv.layers.CutMix(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "def preprocess_data(images, labels, augment=False):\n",
    "    \n",
    "    labels = tf.one_hot(labels, num_classes)\n",
    "    if augment:\n",
    "        # Create a dictionary with \"images\" and \"labels\" keys\n",
    "        outputs = {\"images\": images, \"labels\": labels}\n",
    "        \n",
    "        # Apply augmentations to the dictionary\n",
    "        outputs = augmenter(outputs)\n",
    "        \n",
    "        # Return augmented images and labels\n",
    "        return outputs[\"images\"], outputs[\"labels\"]\n",
    "    \n",
    "    return images, labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Apply preprocessing and augmentations to the train dataset\n",
    "effnet_train_dataset = train_ds.map(\n",
    "    lambda x, y: preprocess_data(x, y, augment=True),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Apply preprocessing to the validation dataset without augmentations\n",
    "effnet_test_dataset = val_ds.map(\n",
    "    lambda x, y: preprocess_data(x, y, augment=False),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use EfficientNetV2Backbone as the backbone"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a model using a pretrained backbone\n",
    "effnet_backbone = keras_cv.models.EfficientNetV2Backbone.from_preset(\n",
    "    \"efficientnetv2_b0_imagenet\"\n",
    ")\n",
    "effnet_model = keras_cv.models.ImageClassifier(\n",
    "    backbone=effnet_backbone,\n",
    "    num_classes=num_classes,\n",
    "    activation=\"softmax\",\n",
    ")\n",
    "effnet_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# Adding this because this optimizer runs slowly on a the M1/M2 chips on a mac\n",
    "effnet_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-5),\n",
    "    metrics=['accuracy']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train your model\n",
    "effnet_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=num_epochs,\n",
    ")\n",
    "\n",
    "effnet_model.save(f\"effnet_{num_epochs}_model.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img = keras.utils.load_img(\"../data/trash_images/cardboard/cardboard_015.jpg\", target_size=image_size)\n",
    "plt.imshow(img)\n",
    "\n",
    "img_array = keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "predictions = effnet_model.predict(img_array)\n",
    "effnet_model.save('effnet_50_epochs.h5')\n",
    "print(f\"Classified as {waste_classes[np.argmin(predictions)]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Effnet Categorical Accuracy\n",
    "This function imports the effnet trained model as well as the metrics saved from file and calculates the accuracy for each of our categories of trash. This is done with the validation dataset. The scores are saved off to a dictionary and will be used later.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import custom_object_scope\n",
    "\n",
    "# Needed to load the effnet model since it uses a custom backbone function that's not\n",
    "# preloaded into the keras load_model function\n",
    "class EfficientNetV2Backbone(keras_cv.models.EfficientNetV2Backbone):\n",
    "    pass\n",
    "\n",
    "class ImageClassifier(keras_cv.models.ImageClassifier):\n",
    "    pass\n",
    "\n",
    "effnet_model_path = 'saved_models/effnet_50_model.h5'\n",
    "with custom_object_scope({'ImageClassifier': ImageClassifier,\n",
    "                          'EfficientNetV2Backbone': EfficientNetV2Backbone}):\n",
    "    effnet_model = tf.keras.models.load_model(effnet_model_path)\n",
    "\n",
    "# Get true labels from the validation dataset\n",
    "val_labels = np.concatenate([batch[1].numpy() for batch in val_ds], axis=0)\n",
    "\n",
    "# Make predictions on the validation dataset\n",
    "val_predictions = effnet_model.predict(val_ds)\n",
    "\n",
    "# Get predicted class indices\n",
    "predicted_labels = np.argmax(val_predictions, axis=1)\n",
    "\n",
    "categories = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "\n",
    "# Initialize Dictionary to store metrics\n",
    "effnet_category_metrics = {}\n",
    "\n",
    "# Calculate accuracy for each category\n",
    "for i, category in enumerate(categories):\n",
    "    true_positive = np.sum((predicted_labels == i) & (val_labels == i))\n",
    "    total_true = np.sum(val_labels == i)\n",
    "    accuracy = true_positive / total_true if total_true > 0 else 0.0\n",
    "    \n",
    "    # Save off and print metrics\n",
    "    effnet_category_metrics[f'{category}'] = accuracy\n",
    "    print(f'Category {category} Accuracy: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Graphing Metrics between different models\n",
    "This function creates graphs of the accuracy, loss, and comparison between the two CNN models. It saves them to png files that can be referenced later."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from keras.utils import custom_object_scope\n",
    "import keras_cv\n",
    "\n",
    "# Needed to load the effnet model since it uses a custom function \n",
    "class EfficientNetV2Backbone(keras_cv.models.EfficientNetV2Backbone):\n",
    "    pass\n",
    "\n",
    "class ImageClassifier(keras_cv.models.ImageClassifier):\n",
    "    pass\n",
    "\n",
    "# Load the saved models\n",
    "model_path = 'saved_models/model_50_epochs.keras'\n",
    "effnet_model_path = 'saved_models/effnet_50_model.h5'\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "with custom_object_scope({'ImageClassifier': ImageClassifier,\n",
    "                          'EfficientNetV2Backbone': EfficientNetV2Backbone}):\n",
    "    effnet_model = tf.keras.models.load_model(effnet_model_path)\n",
    "\n",
    "# Load the training history, saved models don't contain the metrics from the history value assignment, these need to be saved and loaded separately.\n",
    "with open('saved_models/first_training_history.pkl', 'rb') as file:\n",
    "    loaded_history = pickle.load(file)\n",
    "\n",
    "with open('saved_models/effnet_training_history.pkl', 'rb') as file:\n",
    "    effnet_loaded_history = pickle.load(file)\n",
    "\n",
    "# Access loaded training history\n",
    "loaded_training_accuracy = loaded_history['accuracy']\n",
    "loaded_validation_loss = loaded_history['loss']\n",
    "effnet_loaded_training_accuracy = effnet_loaded_history['accuracy']\n",
    "effnet_loaded_training_loss = effnet_loaded_history['loss']\n",
    "\n",
    "# Epoch vars\n",
    "epochs = range(1, len(loaded_training_accuracy) + 1)\n",
    "effnet_epochs = range(1, len(effnet_loaded_training_accuracy) + 1)\n",
    "\n",
    "# Plot Model 1 accuracy\n",
    "plt.plot(epochs, loaded_training_accuracy, 'lightseagreen', label='Model 1 Training Accuracy')\n",
    "plt.title('Model 1 Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('metrics/model1_accuracy.png')\n",
    "# Clear plot \n",
    "plt.clf()\n",
    "\n",
    "# Plot Model 2 accuracy\n",
    "plt.plot(effnet_epochs, effnet_loaded_training_accuracy, 'lightseagreen', label='Effnet Training Accuracy')\n",
    "plt.title('Model 2 Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('metrics/model2_accuracy.png')\n",
    "# Clear plot \n",
    "plt.clf()\n",
    "\n",
    "# Plot Model 1 Loss\n",
    "plt.plot(epochs, loaded_validation_loss, 'darkslategrey', label='Model 1 Training Loss')\n",
    "plt.title('Model 1 Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('metrics/model1_loss.png')\n",
    "# Clear plot \n",
    "plt.clf()\n",
    "\n",
    "# Plot Model 2 loss\n",
    "plt.plot(effnet_epochs, effnet_loaded_training_loss, 'darkslategrey', label='Effnet Loss')\n",
    "plt.title('Model 2 Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('metrics/model2_loss.png')\n",
    "# Clear plot \n",
    "plt.clf()\n",
    "\n",
    "# Plot Model 1 loss and accuracy\n",
    "plt.plot(epochs, loaded_training_accuracy, 'lightseagreen', label='Model 1 Training Accuracy')\n",
    "plt.plot(epochs, loaded_validation_loss, 'darkslategrey', label='Model 1 Training Loss')\n",
    "plt.title('Model 1 Accuracy vs Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy/Loss')\n",
    "plt.legend()\n",
    "plt.savefig('metrics/model1_accuracy_and_loss.png')\n",
    "# Clear plot \n",
    "plt.clf()\n",
    "\n",
    "# Plot Model 2 loss and accuracy\n",
    "plt.plot(effnet_epochs, effnet_loaded_training_accuracy, 'lightseagreen', label='Effnet Training Accuracy')\n",
    "plt.plot(effnet_epochs, effnet_loaded_training_loss, 'darkslategrey', label='Effnet Loss')\n",
    "plt.title('Model 2 Accuracy vs Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy/Loss')\n",
    "plt.legend()\n",
    "plt.savefig('metrics/model2_accuracy_and_loss.png')\n",
    "# Clear plot \n",
    "plt.clf()\n",
    "\n",
    "# Plot Model 1 & 2 accuracy\n",
    "plt.plot(epochs, loaded_training_accuracy, 'blue', label='Model 1 Training Accuracy')\n",
    "plt.plot(effnet_epochs, effnet_loaded_training_accuracy, 'red', label='Effnet Training Accuracy')\n",
    "plt.title('Model 1 Accuracy vs Model 2 Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('metrics/model1_accuracy_vs_mode2_accuracy.png')\n",
    "# Clear plot \n",
    "plt.clf()\n",
    "\n",
    "# Plot Model 1 & 2 loss\n",
    "plt.plot(epochs, loaded_validation_loss, 'blue', label='Model 1 Training Loss')\n",
    "plt.plot(effnet_epochs, effnet_loaded_training_loss, 'red', label='Effnet Training Loss')\n",
    "plt.title('Model 1 Loss vs Model 2 Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('metrics/model1_loss_vs_mode2_loss.png')\n",
    "# Clear plot \n",
    "plt.clf()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot Categorical Accuracy Between Random Forest and the two CNN models\n",
    "This function takes the categorical accuracy scores across all the trained models and compares which categories were easier/harder to classify. It saves off the graph as a png file into the metrics folder."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get categorical accuracy values from random forest metrics csv file\n",
    "random_forest_metrics = pd.read_csv('../src/model_metrics.csv')\n",
    "\n",
    "random_forest_dict = {}\n",
    "\n",
    "# Gather accuracy measures from random forest csv\n",
    "for category in categories:\n",
    "    column_name = f'accuracy_for_{category}'\n",
    "    random_forest_dict[category] = random_forest_metrics[column_name].values[0]\n",
    "    \n",
    "# Initialize the categories using keys from random_forest\n",
    "categories = list(random_forest_dict.keys())\n",
    "\n",
    "# Create bar plot to compare categories across models\n",
    "bar_width = 0.25\n",
    "index = np.arange(len(categories))\n",
    "\n",
    "# Create numpy array for each model to make plotting easier\n",
    "random_forest_data = np.array([random_forest_dict[category] for category in  categories])\n",
    "model_1_data = np.array([result_dict[category] for category in categories])\n",
    "effnet_data = np.array([effnet_category_metrics[category] for category in categories])\n",
    "\n",
    "# Individually plot the data\n",
    "plt.bar(index - bar_width, random_forest_data, width=bar_width, label=\"Random Forest\")\n",
    "plt.bar(index, model_1_data, width=bar_width, label='Model 1')\n",
    "plt.bar(index + bar_width, effnet_data, width=bar_width, label='Effnet Model')\n",
    "\n",
    "# Create labels and show plot       \n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison by Category and Source')\n",
    "plt.xticks(index + bar_width * 1.5, categories)\n",
    "plt.legend()\n",
    "plt.savefig('metrics/categorical_comparison.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
